trigger: none

pr:
  branches:
    include:
      - main

variables:
  - group: dev-variable-group

jobs:
  - job: UnitTests
    displayName: "Unit Tests"

    pool:
      vmImage: "ubuntu-latest"

    steps:
      - checkout: self
        persistCredentials: true
        clean: true
        displayName: "Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)"

      # Install Databricks CLI
      - script: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
        displayName: "Install Databricks CLI"

      # Extract Databricks version to test installation
      - script: |
          databricks version
        displayName: "Get Databricks CLI version"

      # Install unit test dependencies
      - script: |
          cd default_python
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
        displayName: "Install dependencies"

      # Check DB Connect
      - script: |
          databricks-connect test
        env:
          DATABRICKS_HOST: $(DATABRICKS_HOST)
          DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)
          DATABRICKS_CLUSTER_ID: $(DATABRICKS_CLUSTER_ID)
        displayName: "Check DBConnect"

      - script: |
          cd default_python
          pytest --junitxml=test-unit.xml
        displayName: "Run unit tests"
        env:
          DATABRICKS_HOST: $(DATABRICKS_HOST)
          DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)
          DATABRICKS_CLUSTER_ID: $(DATABRICKS_CLUSTER_ID)

      - task: PublishTestResults@2
        condition: succeededOrFailed()
        inputs:
          testResultsFormat: "JUnit"
          testResultsFiles: "**/test-*.xml"
          failTaskOnFailedTests: true

  - job: IntegrationTests
    displayName: "Integration Tests"

    pool:
      vmImage: "ubuntu-latest"

    steps:
      - checkout: self
        persistCredentials: true
        clean: true
        displayName: "Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)"

      # Install Databricks CLI
      - script: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sudo sh
        displayName: "Install Databricks CLI"

      # Extract Databricks version to test installation
      - script: |
          databricks version
        displayName: "Get Databricks CLI version"

      # Validate
      - script: |
          cd default_python
          databricks bundle validate -t dev
        displayName: "Validate bundle"
        env:
          DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)

      # Clean up dev
      - script: |
          cd default_python
          if [ -f ".databricks/bundle/dev/terraform/terraform.tfstate" ]; then
              databricks bundle destroy --auto-approve -t dev
              else
              echo "No resources to destroy. Skipping cleanup."
              fi
        displayName: "Clean up existing bundle files from dev environment"
        continueOnError: true
        env:
          DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)

      # Deploy
      - script: |
          cd default_python
          databricks bundle deploy -t dev
        displayName: "Create bundle files from dev environment"
        env:
          DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)
          BUNDLE_VAR_notifications_email_address: $(BUNDLE_VAR_notifications_email_address)

      # Run
      - script: |
          cd default_python
          databricks bundle run -t dev default_python_job
        displayName: "Run workflow"
        env:
          DATABRICKS_CLIENT_ID: $(DATABRICKS_CLIENT_ID)
          DATABRICKS_CLIENT_SECRET: $(DATABRICKS_CLIENT_SECRET)
